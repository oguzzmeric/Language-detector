# Web Scraping Language Detector ğŸŒ

Bu proje, web scraping kullanarak gerÃ§ek zamanlÄ± metin verilerini toplayan ve Ã§ok dilli dil tanÄ±ma sistemi geliÅŸtiren bir makine Ã¶ÄŸrenmesi uygulamasÄ±dÄ±r.

## ğŸ¯ Proje Ã–zeti

Bu sistem, 9 farklÄ± dildeki haber sitelerinden metin verilerini otomatik olarak toplar, temizler ve bu verileri kullanarak bir dil tanÄ±ma modeli eÄŸitir. EÄŸitilen model, yeni metinlerin hangi dilde yazÄ±ldÄ±ÄŸÄ±nÄ± yÃ¼ksek doÄŸrulukla tespit edebilir.

## ğŸŒ Desteklenen Diller

- ğŸ‡¹ğŸ‡· **TÃ¼rkÃ§e** (Turkish)
- ğŸ‡ºğŸ‡¸ **Ä°ngilizce** (English)
- ğŸ‡©ğŸ‡ª **Almanca** (German)
- ğŸ‡«ğŸ‡· **FransÄ±zca** (French)
- ğŸ‡ªğŸ‡¸ **Ä°spanyolca** (Spanish)
- ğŸ‡·ğŸ‡º **RusÃ§a** (Russian)
- ğŸ‡¨ğŸ‡³ **Ã‡ince** (Chinese)
- ğŸ‡°ğŸ‡· **Korece** (Korean)
- ğŸ‡¯ğŸ‡µ **Japonca** (Japanese)

## ğŸš€ Ã–zellikler

### Web Scraping

- GerÃ§ek zamanlÄ± haber sitelerinden veri toplama
- AkÄ±llÄ± HTML parsing ve temizleme
- Rate limiting ile etik web scraping
- Hata yÃ¶netimi ve gÃ¼venilir veri toplama

### Veri Ä°ÅŸleme

- Otomatik metin temizleme ve Ã¶n iÅŸleme
- TF-IDF vektÃ¶rizasyonu ile Ã¶zellik Ã§Ä±karÄ±mÄ±
- Karakter n-gram analizi (1-3 gram)
- Veri kalitesi kontrolÃ¼

### Makine Ã–ÄŸrenmesi

- Multinomial Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±
- Stratified train-test split
- DetaylÄ± performans deÄŸerlendirmesi
- Model kaydetme ve yÃ¼kleme

### EtkileÅŸimli Test

- GerÃ§ek zamanlÄ± dil tanÄ±ma testi
- GÃ¼ven skoru ile tahmin gÃ¼venilirliÄŸi
- KullanÄ±cÄ± dostu arayÃ¼z

## ğŸ“‹ Gereksinimler

### Python KÃ¼tÃ¼phaneleri

```bash
pip install pandas numpy matplotlib seaborn
pip install scikit-learn nltk
pip install requests beautifulsoup4
pip install pickle
```

### Sistem Gereksinimleri

- Python 3.7+
- Ä°nternet baÄŸlantÄ±sÄ± (web scraping iÃ§in)
- En az 4GB RAM (bÃ¼yÃ¼k veri setleri iÃ§in)

## ğŸ› ï¸ Kurulum

1. **Projeyi klonlayÄ±n:**

```bash
git clone <repository-url>
cd new3
```

2. **Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:**

```bash
pip install -r requirements.txt
```

3. **Projeyi Ã§alÄ±ÅŸtÄ±rÄ±n:**

```bash
python dl.py
```

## ğŸ“Š KullanÄ±m

### Temel KullanÄ±m

```python
from dl import WebScrapingLanguageDetector

# Detector oluÅŸtur
detector = WebScrapingLanguageDetector()

# Veri topla ve modeli eÄŸit
data = detector.collect_data_from_web()
detector.prepare_data()
x_train, x_test, y_train, y_test = detector.extract_features()
detector.train_model(x_train, y_train)

# Modeli deÄŸerlendir
accuracy = detector.evaluate_model(x_test, y_test)

# Modeli kaydet
detector.save_model()
```

### Dil TanÄ±ma

```python
# Tek metin iÃ§in dil tanÄ±ma
text = "Hello, how are you today?"
language, confidence = detector.predict_language(text)
print(f"Dil: {language}, GÃ¼ven: {confidence:.2f}")
```

### EtkileÅŸimli Test

```python
# EtkileÅŸimli test modu
detector.interactive_test()
```

## ğŸ”§ YapÄ±landÄ±rma

### Web Scraping AyarlarÄ±

```python
# Her dil iÃ§in maksimum metin sayÄ±sÄ±
max_texts_per_language = 30

# Her URL iÃ§in maksimum metin sayÄ±sÄ±
max_texts_per_url = 10

# Ä°stekler arasÄ± bekleme sÃ¼resi (saniye)
time.sleep(random.uniform(2, 4))
```

### Model Parametreleri

```python
# TF-IDF Vectorizer ayarlarÄ±
vectorizer = TfidfVectorizer(
    analyzer='char',           # Karakter bazlÄ± analiz
    ngram_range=(1,3),         # 1-3 karakter n-gram
    max_features=2000,         # Maksimum Ã¶zellik sayÄ±sÄ±
    min_df=2,                  # Minimum dokÃ¼man frekansÄ±
    max_df=0.95                # Maksimum dokÃ¼man frekansÄ±
)

# Naive Bayes ayarlarÄ±
model = MultinomialNB(alpha=0.1)  # Smoothing parametresi
```

## ğŸ“ˆ Performans

### Model PerformansÄ±

- **DoÄŸruluk:** %85-95 (veri kalitesine baÄŸlÄ±)
- **EÄŸitim SÃ¼resi:** 1-3 dakika
- **Tahmin SÃ¼resi:** <1 saniye
- **Desteklenen Metin UzunluÄŸu:** 20-500 karakter

### Web Scraping PerformansÄ±

- **Toplam Veri Toplama SÃ¼resi:** 5-10 dakika
- **Ortalama Metin SayÄ±sÄ±:** 200-300 metin
- **BaÅŸarÄ± OranÄ±:** %90+ (site eriÅŸilebilirliÄŸine baÄŸlÄ±)

## ğŸ—‚ï¸ Dosya YapÄ±sÄ±

```
new3/
â”œâ”€â”€ dl.py                              # Ana uygulama dosyasÄ±
â”œâ”€â”€ web_scraped_language_detector.pkl  # EÄŸitilmiÅŸ model
â”œâ”€â”€ requirements.txt                   # Python gereksinimleri
â””â”€â”€ README.md                          # Bu dosya
```

## ğŸ” Teknik Detaylar

### Veri Toplama SÃ¼reci

1. **URL Listesi:** Her dil iÃ§in 3 haber sitesi
2. **HTML Parsing:** BeautifulSoup ile iÃ§erik Ã§Ä±karÄ±mÄ±
3. **Metin Filtreleme:** 20-500 karakter arasÄ± metinler
4. **Temizleme:** Script, style, nav elementlerinin kaldÄ±rÄ±lmasÄ±

### Ã–zellik Ã‡Ä±karÄ±mÄ±

- **TF-IDF VektÃ¶rizasyonu:** Metinleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rme
- **Karakter N-gram:** 1-3 karakter kombinasyonlarÄ±
- **Ã–zellik SeÃ§imi:** En Ã¶nemli 2000 Ã¶zelliÄŸin seÃ§ilmesi

### Model EÄŸitimi

- **Algoritma:** Multinomial Naive Bayes
- **Cross-validation:** Stratified split ile dengeli daÄŸÄ±lÄ±m
- **Hyperparameter:** Alpha=0.1 smoothing

## ğŸš¨ Ã–nemli Notlar

### Etik KullanÄ±m

- Web sitelerinin robots.txt dosyalarÄ±na saygÄ± gÃ¶sterin
- Rate limiting kullanarak sunucularÄ± aÅŸÄ±rÄ± yÃ¼klemeyin
- Telif hakkÄ± olan iÃ§erikleri ticari amaÃ§la kullanmayÄ±n

### Hata YÃ¶netimi

- Ä°nternet baÄŸlantÄ±sÄ± kesintilerinde otomatik yeniden deneme
- EriÅŸilemeyen siteler iÃ§in alternatif URL'ler
- Veri kalitesi kontrolÃ¼ ve filtreleme

### Performans Optimizasyonu

- BÃ¼yÃ¼k veri setleri iÃ§in batch processing
- Model caching ile hÄ±zlÄ± yeniden yÃ¼kleme
- Memory-efficient veri yapÄ±larÄ±

## ğŸ”® Gelecek GeliÅŸtirmeler

- [ ] Daha fazla dil desteÄŸi
- [ ] Deep learning modelleri (LSTM, BERT)
- [ ] Web arayÃ¼zÃ¼ geliÅŸtirme
- [ ] API endpoint'leri
- [ ] GerÃ§ek zamanlÄ± streaming analizi
- [ ] Ã‡oklu model ensemble

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/AmazingFeature`)
3. Commit yapÄ±n (`git commit -m 'Add some AmazingFeature'`)
4. Push yapÄ±n (`git push origin feature/AmazingFeature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ“ Ä°letiÅŸim

Proje hakkÄ±nda sorularÄ±nÄ±z iÃ§in:

- **Email:** [your-email@example.com]
- **GitHub:** [your-github-username]

## ğŸ™ TeÅŸekkÃ¼rler

- **scikit-learn** - Makine Ã¶ÄŸrenmesi kÃ¼tÃ¼phanesi
- **BeautifulSoup** - HTML parsing
- **requests** - HTTP istekleri
- **pandas** - Veri manipÃ¼lasyonu

---

â­ **Bu projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!**
